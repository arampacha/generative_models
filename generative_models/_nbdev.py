# AUTOGENERATED BY NBDEV! DO NOT EDIT!

__all__ = ["index", "modules", "custom_doc_links", "git_url"]

index = {"identity": "00_layers.ipynb",
         "Identity": "00_layers.ipynb",
         "exist": "00_layers.ipynb",
         "ifnone": "00_layers.ipynb",
         "scale": "00_layers.ipynb",
         "unscale": "00_layers.ipynb",
         "trainable_parameters": "00_layers.ipynb",
         "FullyConnected": "00_layers.ipynb",
         "MLP": "00_layers.ipynb",
         "Conv2dBlock": "00_layers.ipynb",
         "ConvTranspose2dBlock": "00_layers.ipynb",
         "ResBlock": "00_layers.ipynb",
         "ChanLayerNorm": "00_layers.ipynb",
         "ConvNet": "00_layers.ipynb",
         "AverageMeter": "01_training.ipynb",
         "make_masks": "02_made.ipynb",
         "MaskedLinear": "02_made.ipynb",
         "SimpleMADE": "02_made.ipynb",
         "MADE": "02_made.ipynb",
         "MaskedConv2d": "03_pixelcnn.ipynb",
         "make_mask_a": "03_pixelcnn.ipynb",
         "make_mask_b": "03_pixelcnn.ipynb",
         "SimplePixelCNN": "03_pixelcnn.ipynb",
         "PixelCNNResBlock": "03_pixelcnn.ipynb",
         "PixelCNN": "03_pixelcnn.ipynb",
         "VAEOutput": "04_vae.ipynb",
         "VAE": "04_vae.ipynb",
         "VQPseudoGrad": "04_vae.ipynb",
         "VectorQuantizer": "04_vae.ipynb",
         "VectorQuantizerEMA": "04_vae.ipynb"}

modules = ["layers.py",
           "training.py",
           "made.py",
           "pixelcnn.py",
           "vae.py"]

doc_url = "https://arampacha.github.io/generative_models/"

git_url = "https://github.com/arampacha/generative_models/tree/master/"

def custom_doc_links(name): return None
