{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# default_exp pixelcnn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PixelCNN model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from typing import Sequence, Union, Tuple\n",
    "\n",
    "from generative_models.layers import exist, scale, unscale, ChanLayerNorm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# hide\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# export\n",
    "class MaskedConv2d(nn.Module):\n",
    "    def __init__(self, c_in, c_out, ks, mask, stride=1, padding=None, d_cond:int=None):\n",
    "        super().__init__()\n",
    "        if padding is None: padding = (ks-1)//2\n",
    "        self.stride, self.padding = stride, padding\n",
    "        self.weight = nn.Parameter(torch.randn(c_out, c_in, ks, ks))\n",
    "        self.bias = nn.Parameter(torch.zeros(c_out))\n",
    "        self.register_buffer('mask', mask[None, None])\n",
    "        nn.init.kaiming_normal_(self.weight)\n",
    "        if d_cond is not None:\n",
    "            self.cond_proj = nn.Linear(d_cond, c_out)\n",
    "        else:\n",
    "            self.cond_proj = None\n",
    "\n",
    "    def forward(self, x, cond=None):\n",
    "        out = F.conv2d(x, self.weight*self.mask, self.bias, self.stride, self.padding)\n",
    "        if exist(self.cond_proj) and exist(cond):\n",
    "            out += self.cond_proj(cond)[..., None, None]\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# export\n",
    "def make_mask_a(ks:int):\n",
    "    n = ks*ks\n",
    "    mask = torch.arange(n).reshape(ks,ks)\n",
    "    mask = (mask < n//2).float()\n",
    "    return mask\n",
    "\n",
    "def make_mask_b(ks:int):\n",
    "    n = ks*ks\n",
    "    mask = torch.arange(n).reshape(ks,ks)\n",
    "    mask = (mask <= n//2).float()\n",
    "    return mask\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(make_mask_a(5).numpy())\n",
    "axs[0].set_title(\"Type A mask\")\n",
    "axs[1].imshow(make_mask_b(5).numpy())\n",
    "axs[1].set_title(\"Type B mask\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# export\n",
    "class SimplePixelCNN(nn.Module):\n",
    "    \"Simple PixelCNN\"\n",
    "    def __init__(self, nh:int=64, ks:int=7, n_layers:int=8, d_cond:int=None, size=20):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers += [MaskedConv2d(1, nh, ks, make_mask_a(ks), d_cond=d_cond), ChanLayerNorm(nh), nn.ReLU()]\n",
    "        for _ in range(n_layers-3):\n",
    "            layers += [MaskedConv2d(nh,nh, ks, make_mask_b(ks), d_cond=d_cond), ChanLayerNorm(nh), nn.ReLU()]\n",
    "        layers += [nn.Conv2d(nh, nh//2, 1), nn.ReLU()]\n",
    "        layers += [nn.Conv2d(nh//2, 1,  1)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, cond=None):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l, MaskedConv2d):\n",
    "                x = l(x, cond)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x\n",
    "\n",
    "    def sample(self, d:int, n:int=16, cond=None):\n",
    "        \n",
    "        if exist(cond):\n",
    "            if cond.size(0) != n:\n",
    "                print(f\"Number of provided conditional inputs ({cond.size(0)}) should match number of samples ({n})!\")\n",
    "                n = cond.size(0)\n",
    "        \n",
    "        x = torch.ones(n,1,d,d)\n",
    "        for i in range(d):\n",
    "            for j in range(d):\n",
    "                out = self(x, cond)\n",
    "                x[:, :, i, j] = scale((torch.sigmoid(out[:, :, i, j]) > torch.rand(x.size(0),1)).float())\n",
    "        return unscale(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "x = torch.randn(4,1,8,8)\n",
    "model = SimplePixelCNN()\n",
    "out = model(x)\n",
    "assert out.shape == x.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# slow\n",
    "res = model.sample(n=4, d=8)\n",
    "assert res.shape == (4,1,8,8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# hide\n",
    "c = torch.rand(10)\n",
    "x = torch.randn(4,1,8,8)\n",
    "model = SimplePixelCNN(d_cond=10)\n",
    "out = model(x, c)\n",
    "assert out.shape == x.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# export\n",
    "class PixelCNNResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_out, ks, mask, stride=1, padding=None, d_cond:int=None) -> None:\n",
    "        super().__init__()\n",
    "        h = c_out // 2\n",
    "        self.net = nn.ModuleList([\n",
    "            nn.Conv2d(c_in, h, 1),\n",
    "            nn.ReLU(),\n",
    "            MaskedConv2d(h, h, ks, mask, stride, padding, d_cond),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(h, c_out, 1)\n",
    "        ])\n",
    "        self.norm = ChanLayerNorm(c_in)\n",
    "        \n",
    "    def forward(self, x, cond=None):\n",
    "        x = self.norm(x)\n",
    "        res = x\n",
    "        for l in self.net:\n",
    "            if isinstance(l, MaskedConv2d):\n",
    "                res = l(res, cond)\n",
    "            else:\n",
    "                res = l(res)\n",
    "        return x + res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "x = torch.randn(4,16,8,8)\n",
    "m = PixelCNNResBlock(16, 16, 5, make_mask_b(5))\n",
    "out = m(x)\n",
    "assert out.shape == x.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# export\n",
    "class PixelCNN(nn.Module):\n",
    "    \"PixelCNN\"\n",
    "    def __init__(self, nh:int=64, ks:int=7, n_layers:int=8, d_cond:int=None, size=20):\n",
    "        super().__init__()\n",
    "        layers = [MaskedConv2d(1, nh, ks, make_mask_a(ks), d_cond=d_cond), ChanLayerNorm(nh), nn.ReLU()]\n",
    "        for _ in range(n_layers-3):\n",
    "            layers += [PixelCNNResBlock(nh,nh, ks, make_mask_b(ks), d_cond=d_cond)]\n",
    "        layers += [nn.Conv2d(nh, nh//2, 1), nn.ReLU()]\n",
    "        layers += [nn.Conv2d(nh//2, 1,  1)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, cond=None):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l, MaskedConv2d):\n",
    "                x = l(x, cond)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x\n",
    "\n",
    "    def sample(self, d:int, n:int=16, cond=None):\n",
    "        \n",
    "        if exist(cond):\n",
    "            if cond.size(0) != n:\n",
    "                print(f\"Number of provided conditional inputs ({cond.size(0)}) should match number of samples ({n})!\")\n",
    "                n = cond.size(0)\n",
    "        \n",
    "        x = torch.ones(n,1,d,d)\n",
    "        for i in range(d):\n",
    "            for j in range(d):\n",
    "                out = self(x, cond)\n",
    "                x[:, :, i, j] = scale((torch.sigmoid(out[:, :, i, j]) > torch.rand(x.size(0),1)).float())\n",
    "        return unscale(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted 00_layers.ipynb.\n",
      "Converted 01_training.ipynb.\n",
      "Converted 02_made.ipynb.\n",
      "Converted 03_pixelcnn.ipynb.\n",
      "Converted 04_vae.ipynb.\n",
      "Converted 10_experiments.pixelcnn.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('torchenv': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "4af15c6377fd3f0f03723b0d6472f0c10dcd7b2afd49a75a2b51cefc0e0a1d19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}