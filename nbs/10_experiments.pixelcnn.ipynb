{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# all_slow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from generative_models.layers import scale, unscale"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dir = \"/media/arto/work/data/mnist\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from pathlib import Path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "path = Path(dir)\n",
    "path.exists()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# train_dl = DataLoader(MNIST(dir, transform=T.ToTensor()), batch_size=128, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(MNIST(dir, transform=T.ToTensor(), train=False), batch_size=32, shuffle=False, drop_last=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/arto/anaconda3/envs/torchenv/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "b = next(iter(valid_dl))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "b[0].shape, b[1].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from generative_models.layers import ConvNet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = nn.Sequential(\n",
    "    ConvNet(1),\n",
    "    nn.Flatten(),\n",
    "    nn.BatchNorm1d(64*2*2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64*2*2, 10)\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "out = model(b[0])\n",
    "out.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from tqdm.auto import tqdm, trange"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def train_step(batch, model, optimizer, loss_func, scheduler=None, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    xb, yb = batch[0].to(device), batch[1].to(device)\n",
    "    preds = model(xb)\n",
    "\n",
    "    loss = loss_func(preds, yb)\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "    optimizer.step()\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss.item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def accuracy(pred, targ):\n",
    "    return (pred.argmax(-1) == targ).float().mean()\n",
    "def eval_step(batch, model, loss_func, device=None):\n",
    "    if device == None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    xb, yb = batch[0].to(device), batch[1].to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "    return loss.item(), accuracy(preds, yb).item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def fit(n_epoch, model, train_dl, valid_dl, train_step, eval_step, optimizer, loss_func, scheduler=None, device=None):\n",
    "    \n",
    "    if device == None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    steps_per_epoch = len(train_dl)\n",
    "    total_steps = n_epoch * steps_per_epoch\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    for e in trange(n_epoch):\n",
    "        \n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_dl, leave=False)\n",
    "        for step, batch in enumerate(train_pbar):\n",
    "            total_step = (e*steps_per_epoch)+step\n",
    "            loss = train_step(batch, model, optimizer, loss_func, scheduler, device=device)\n",
    "            train_losses.append(loss)\n",
    "            train_pbar.set_description(f\"{loss:.2f}\")\n",
    "\n",
    "        model.eval()\n",
    "        avg_valid_loss = 0\n",
    "        for step, batch in enumerate(valid_dl):\n",
    "            loss = eval_step(batch, model, loss_func, device=device)\n",
    "            avg_valid_loss += (loss-avg_valid_loss) / (step+1)\n",
    "        valid_losses.append(avg_valid_loss)\n",
    "    return train_losses, valid_losses, valid_accs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "tl, vl, va = fit(2, model, train_dl, valid_dl, train_step, eval_step, optimizer, nn.CrossEntropyLoss())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2/2 [00:30<00:00, 15.36s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "va"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.9798259493670884, 0.9860561708860759]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from generative_models.pixelcnn import SimplePixelCNN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = SimplePixelCNN(ks=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SimplePixelCNN(\n",
       "  (layers): ModuleList(\n",
       "    (0): MaskedConv2d()\n",
       "    (1): ChanLayerNorm(\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): ReLU()\n",
       "    (3): MaskedConv2d()\n",
       "    (4): ChanLayerNorm(\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): ReLU()\n",
       "    (6): MaskedConv2d()\n",
       "    (7): ChanLayerNorm(\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): ReLU()\n",
       "    (9): MaskedConv2d()\n",
       "    (10): ChanLayerNorm(\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (11): ReLU()\n",
       "    (12): MaskedConv2d()\n",
       "    (13): ChanLayerNorm(\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (14): ReLU()\n",
       "    (15): MaskedConv2d()\n",
       "    (16): ChanLayerNorm(\n",
       "      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (19): ReLU()\n",
       "    (20): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def train_step(batch, model, optimizer, loss_func, scheduler=None, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    xb = scale(batch[0].to(device))\n",
    "    preds = model(xb)\n",
    "\n",
    "    loss = loss_func(preds, xb)\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "    optimizer.step()\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss.item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def eval_step(batch, model, loss_func, device=None):\n",
    "    if device == None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    xb = scale(batch[0].to(device))\n",
    "    with torch.no_grad():\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, xb)\n",
    "    return loss.item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "fit(1, model, valid_dl, valid_dl, train_step, eval_step, optimizer, nn.MSELoss())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [01:13<00:00, 73.23s/it]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([0.025165459141135216,\n",
       "  0.0241972878575325,\n",
       "  0.026837032288312912,\n",
       "  0.02695108950138092,\n",
       "  0.024686306715011597,\n",
       "  0.024144113063812256,\n",
       "  0.024485789239406586,\n",
       "  0.025522911921143532,\n",
       "  0.023379918187856674,\n",
       "  0.02602148987352848,\n",
       "  0.022684287279844284,\n",
       "  0.023620959371328354,\n",
       "  0.024264581501483917,\n",
       "  0.025816742330789566,\n",
       "  0.03121105395257473,\n",
       "  0.02405347116291523,\n",
       "  0.02727814018726349,\n",
       "  0.025518158450722694,\n",
       "  0.024460557848215103,\n",
       "  0.023682404309511185,\n",
       "  0.02358895353972912,\n",
       "  0.022790253162384033,\n",
       "  0.02382190153002739,\n",
       "  0.020986245945096016,\n",
       "  0.02433934435248375,\n",
       "  0.027637461200356483,\n",
       "  0.021911630406975746,\n",
       "  0.027573779225349426,\n",
       "  0.02243075519800186,\n",
       "  0.02319721318781376,\n",
       "  0.021680839359760284,\n",
       "  0.024634309113025665,\n",
       "  0.024297423660755157,\n",
       "  0.02423711121082306,\n",
       "  0.024424802511930466,\n",
       "  0.02504887990653515,\n",
       "  0.02586372010409832,\n",
       "  0.024227755144238472,\n",
       "  0.024355586618185043,\n",
       "  0.025468679144978523,\n",
       "  0.022759485989809036,\n",
       "  0.024881746619939804,\n",
       "  0.02257918380200863,\n",
       "  0.025725701823830605,\n",
       "  0.026492837816476822,\n",
       "  0.02530582621693611,\n",
       "  0.02390533685684204,\n",
       "  0.025783071294426918,\n",
       "  0.0238608680665493,\n",
       "  0.025114314630627632,\n",
       "  0.023457864299416542,\n",
       "  0.021376343443989754,\n",
       "  0.02280452661216259,\n",
       "  0.02397243119776249,\n",
       "  0.023884544149041176,\n",
       "  0.022695979103446007,\n",
       "  0.023002570495009422,\n",
       "  0.02118225023150444,\n",
       "  0.021862516179680824,\n",
       "  0.024464109912514687,\n",
       "  0.023088745772838593,\n",
       "  0.027473362162709236,\n",
       "  0.02324155904352665,\n",
       "  0.022978996858000755,\n",
       "  0.024906586855649948,\n",
       "  0.026165805757045746,\n",
       "  0.021497782319784164,\n",
       "  0.02486112155020237,\n",
       "  0.026769131422042847,\n",
       "  0.024408008903265,\n",
       "  0.022072896361351013,\n",
       "  0.025104960426688194,\n",
       "  0.02379155531525612,\n",
       "  0.023406982421875,\n",
       "  0.02602103166282177,\n",
       "  0.02647869661450386,\n",
       "  0.023457717150449753,\n",
       "  0.023323904722929,\n",
       "  0.023111121729016304,\n",
       "  0.025673648342490196,\n",
       "  0.021267922595143318,\n",
       "  0.023930219933390617,\n",
       "  0.024572828784585,\n",
       "  0.023443875834345818,\n",
       "  0.024176975712180138,\n",
       "  0.025413138791918755,\n",
       "  0.023457955569028854,\n",
       "  0.02512156218290329,\n",
       "  0.024724697694182396,\n",
       "  0.024355048313736916,\n",
       "  0.025202030315995216,\n",
       "  0.0233379527926445,\n",
       "  0.02537531964480877,\n",
       "  0.024419642984867096,\n",
       "  0.024168873205780983,\n",
       "  0.025372834876179695,\n",
       "  0.021566633135080338,\n",
       "  0.022312216460704803,\n",
       "  0.02339460887014866,\n",
       "  0.02335943654179573,\n",
       "  0.02286761999130249,\n",
       "  0.024069583043456078,\n",
       "  0.02299763262271881,\n",
       "  0.024788372218608856,\n",
       "  0.02612309902906418,\n",
       "  0.02105853706598282,\n",
       "  0.02346302755177021,\n",
       "  0.020712271332740784,\n",
       "  0.02371399477124214,\n",
       "  0.024197915568947792,\n",
       "  0.02347218617796898,\n",
       "  0.02439768612384796,\n",
       "  0.0230949018150568,\n",
       "  0.022821007296442986,\n",
       "  0.02215844951570034,\n",
       "  0.024015061557292938,\n",
       "  0.025144703686237335,\n",
       "  0.02578580379486084,\n",
       "  0.023501185700297356,\n",
       "  0.02657381258904934,\n",
       "  0.024089213460683823,\n",
       "  0.024063074961304665,\n",
       "  0.02195393294095993,\n",
       "  0.02583802491426468,\n",
       "  0.021901212632656097,\n",
       "  0.022325554862618446,\n",
       "  0.02300158701837063,\n",
       "  0.025041064247488976,\n",
       "  0.026960279792547226,\n",
       "  0.02522105537354946,\n",
       "  0.021093396469950676,\n",
       "  0.02450494095683098,\n",
       "  0.025845075026154518,\n",
       "  0.02267463319003582,\n",
       "  0.02112670987844467,\n",
       "  0.020963918417692184,\n",
       "  0.023587577044963837,\n",
       "  0.02317025698721409,\n",
       "  0.022468430921435356,\n",
       "  0.025481851771473885,\n",
       "  0.024890322238206863,\n",
       "  0.022805172950029373,\n",
       "  0.02397787757217884,\n",
       "  0.019549598917365074,\n",
       "  0.02575957030057907,\n",
       "  0.022585367783904076,\n",
       "  0.021560844033956528,\n",
       "  0.021041139960289,\n",
       "  0.02599845640361309,\n",
       "  0.020979739725589752,\n",
       "  0.02433830313384533,\n",
       "  0.02242334745824337,\n",
       "  0.02542181871831417,\n",
       "  0.02057849057018757,\n",
       "  0.022531844675540924,\n",
       "  0.021685779094696045,\n",
       "  0.021656449884176254,\n",
       "  0.021948736160993576,\n",
       "  0.02299417555332184,\n",
       "  0.021928494796156883,\n",
       "  0.023646514862775803,\n",
       "  0.02225734293460846,\n",
       "  0.019448695704340935,\n",
       "  0.020208723843097687,\n",
       "  0.022729674354195595,\n",
       "  0.021178023889660835,\n",
       "  0.018310856074094772,\n",
       "  0.018417319282889366,\n",
       "  0.02125641703605652,\n",
       "  0.02602696791291237,\n",
       "  0.024881508201360703,\n",
       "  0.020985197275877,\n",
       "  0.020271971821784973,\n",
       "  0.025957301259040833,\n",
       "  0.02347690612077713,\n",
       "  0.021598681807518005,\n",
       "  0.023501837626099586,\n",
       "  0.023947104811668396,\n",
       "  0.02603798359632492,\n",
       "  0.03159287944436073,\n",
       "  0.031831443309783936,\n",
       "  0.026348832994699478,\n",
       "  0.0343405082821846,\n",
       "  0.025207186117768288,\n",
       "  0.023540304973721504,\n",
       "  0.02413264848291874,\n",
       "  0.026873739436268806,\n",
       "  0.024189038202166557,\n",
       "  0.024454500526189804,\n",
       "  0.027473989874124527,\n",
       "  0.02748546190559864,\n",
       "  0.02459084242582321,\n",
       "  0.0238484013825655,\n",
       "  0.027678707614541054,\n",
       "  0.02335665188729763,\n",
       "  0.025333024561405182,\n",
       "  0.02472667209804058,\n",
       "  0.024130864068865776,\n",
       "  0.025703273713588715,\n",
       "  0.026213781908154488,\n",
       "  0.02476911060512066,\n",
       "  0.022833144292235374,\n",
       "  0.02583354339003563,\n",
       "  0.025308700278401375,\n",
       "  0.03465501219034195,\n",
       "  0.03803979977965355,\n",
       "  0.035219017416238785,\n",
       "  0.030053766444325447,\n",
       "  0.024381550028920174,\n",
       "  0.02685229666531086,\n",
       "  0.025999223813414574,\n",
       "  0.026855219155550003,\n",
       "  0.023904580622911453,\n",
       "  0.022557411342859268,\n",
       "  0.023349924013018608,\n",
       "  0.021553078666329384,\n",
       "  0.02308019809424877,\n",
       "  0.02422638237476349,\n",
       "  0.026050951331853867,\n",
       "  0.023471081629395485,\n",
       "  0.02376311644911766,\n",
       "  0.02385307289659977,\n",
       "  0.027241097763180733,\n",
       "  0.020413585007190704,\n",
       "  0.025587936863303185,\n",
       "  0.024397343397140503,\n",
       "  0.024883849546313286,\n",
       "  0.02238272689282894,\n",
       "  0.02007526531815529,\n",
       "  0.020831691101193428,\n",
       "  0.024442030116915703,\n",
       "  0.025325920432806015,\n",
       "  0.024939093738794327,\n",
       "  0.026198776438832283,\n",
       "  0.023531440645456314,\n",
       "  0.027303189039230347,\n",
       "  0.024468688294291496,\n",
       "  0.023554811254143715,\n",
       "  0.02559882216155529,\n",
       "  0.025031255558133125,\n",
       "  0.023582009598612785,\n",
       "  0.028882097452878952,\n",
       "  0.0238957479596138,\n",
       "  0.028554128482937813,\n",
       "  0.02276710607111454,\n",
       "  0.027564996853470802,\n",
       "  0.021403536200523376,\n",
       "  0.022596275433897972,\n",
       "  0.022736798971891403,\n",
       "  0.024414684623479843,\n",
       "  0.022932883352041245,\n",
       "  0.024850761517882347,\n",
       "  0.022712837904691696,\n",
       "  0.026667360216379166,\n",
       "  0.027201592922210693,\n",
       "  0.028042461723089218,\n",
       "  0.025886354967951775,\n",
       "  0.02472769282758236,\n",
       "  0.02901526354253292,\n",
       "  0.02679613046348095,\n",
       "  0.028164340183138847,\n",
       "  0.027648895978927612,\n",
       "  0.026996655389666557,\n",
       "  0.022718511521816254,\n",
       "  0.02694959193468094,\n",
       "  0.026176830753684044,\n",
       "  0.02474903129041195,\n",
       "  0.033413391560316086,\n",
       "  0.029690910130739212,\n",
       "  0.025709200650453568,\n",
       "  0.025660455226898193,\n",
       "  0.023668626323342323,\n",
       "  0.021615786477923393,\n",
       "  0.02161114476621151,\n",
       "  0.021664949133992195,\n",
       "  0.023062439635396004,\n",
       "  0.022212594747543335,\n",
       "  0.0198417566716671,\n",
       "  0.023466579616069794,\n",
       "  0.026169072836637497,\n",
       "  0.02710454724729061,\n",
       "  0.02432725764811039,\n",
       "  0.026151597499847412,\n",
       "  0.030023476108908653,\n",
       "  0.028260376304388046,\n",
       "  0.022534234449267387,\n",
       "  0.022489726543426514,\n",
       "  0.023435840383172035,\n",
       "  0.025000054389238358,\n",
       "  0.021607132628560066,\n",
       "  0.021713221445679665,\n",
       "  0.022083522751927376,\n",
       "  0.021455204114317894,\n",
       "  0.024627400562167168,\n",
       "  0.026595305651426315,\n",
       "  0.022242818027734756,\n",
       "  0.02569037303328514,\n",
       "  0.026715263724327087,\n",
       "  0.024584496393799782,\n",
       "  0.026699766516685486,\n",
       "  0.03223850950598717,\n",
       "  0.03106926567852497,\n",
       "  0.031985681504011154,\n",
       "  0.027505287900567055,\n",
       "  0.026301559060811996,\n",
       "  0.02268313430249691,\n",
       "  0.018367260694503784,\n",
       "  0.02044326439499855,\n",
       "  0.017256345599889755,\n",
       "  0.02240048348903656,\n",
       "  0.027537135407328606,\n",
       "  0.022784797474741936,\n",
       "  0.024278679862618446],\n",
       " [0.024526611024055622],\n",
       " [])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('torchenv': conda)"
  },
  "interpreter": {
   "hash": "4af15c6377fd3f0f03723b0d6472f0c10dcd7b2afd49a75a2b51cefc0e0a1d19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}