{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# default_exp made"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MADE model\n",
    "\n",
    "> Masked Autoencoder for Distribution Estimation https://arxiv.org/abs/1502.03509."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Sequence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# hide\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "d, k = 2,4\n",
    "m = torch.randint(0, d-1, (k,))\n",
    "i = torch.arange(d)\n",
    "j = torch.arange(k)\n",
    "input_mask = torch.where(m[j][..., None] >= i[None], 1., 0.)\n",
    "input_mask\n",
    "output_mask = torch.where(i[..., None] > m[j][None], 1., 0.)\n",
    "output_mask\n",
    "output_mask @ input_mask\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [4., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# export\n",
    "def make_masks(d:int, ks:Sequence):\n",
    "    L = len(ks)\n",
    "    ms = [torch.arange(d)]\n",
    "    masks = []\n",
    "    for l, k in enumerate(ks):\n",
    "        m = torch.randint(min(ms[l]), d-1, (k,))\n",
    "        ms.append(m)\n",
    "        mask = torch.where(ms[l+1][..., None] >= ms[l][None], 1., 0.)\n",
    "        masks.append(mask)\n",
    "    mask = torch.where(ms[0][..., None] > ms[-1][None], 1., 0.)\n",
    "    masks.append(mask)\n",
    "    return masks\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "masks = make_masks(2, [4]*3)\n",
    "torch.linalg.multi_dot(masks[::-1]).bool().float()\n",
    "for mask in masks:\n",
    "    print(mask.shape)\n",
    "fig, axs = plt.subplots(1, len(masks))\n",
    "for ax, mask in zip(axs, masks):\n",
    "    ax.matshow(mask)\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 2])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAEICAYAAAADc72lAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZCUlEQVR4nO3db2hUd77H8c9Em1FwZrhBEnbI6M2urGhzk2oiMqISZc0yC8HcRz4KKcQH1ihInmxVWP9AGWnBKohBWdFHNlLaqA80S9huEkUCTa5BsWCRa29SjFpLOzMZcDTx3AfdZDfVqCf5nXMyJ+8XDGVOJ/P9Jvm288mZ35xfwLIsSwAAAAYUeN0AAADwD4IFAAAwhmABAACMIVgAAABjCBYAAMAYggUAADCGYAEAAIwhWAAAAGMIFgAAwBiCBQAAMMa3weLkyZMqKyvTggULVFVVpWvXrnnd0oz19PSorq5O0WhUgUBAFy9e9LolAAAm8WWwuHDhgvbs2aP9+/fr5s2b2rBhgxKJhAYHB71ubUay2awqKyt14sQJr1sBAOCVAn7chGzt2rVavXq1WltbJ46tWLFC9fX1SiaTHnZmTiAQUHt7u+rr671uBQCACb47Y/Hs2TP19/ertrZ20vHa2lrduHHDo64AAJgbfBcsnjx5orGxMZWUlEw6XlJSoocPH3rUFQAAc4PvgsW4QCAw6b5lWS8dAwAAZvkuWCxevFjz5s176ezE48ePXzqLAQAAzPJdsCgsLFRVVZU6OzsnHe/s7NS6des86goAgLlhvtcNOKGlpUUNDQ2qrq5WPB7X6dOnNTg4qB07dnjd2oyMjIzo3r17E/fv37+vgYEBFRUVacmSJR52BgDAL3z5cVPplwtkffzxxxoeHlZ5ebk+/fRTbdy40eu2ZqSrq0ubNm166XhjY6POnTvnfkMAAPyKb4MFAABwn+/WWAAAAO8QLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMb4OFrlcTgcPHlQul/O6FWP8+D0BAPzD19exSKfTikQiSqVSCofDXrdjhB+/JwCAf/j6jAUAAHAXwQIAABjj+iZkL1680IMHDxQKhRQIBBytlU6nJ/3TD9z8nizLUiaTUTQaVUEBGRQA8Gaur7H4/vvvFYvF3CyJGRoaGlJpaanXbQAA8oDrZyxCoZAk6f/+5z8VXuSvv4L/+/f/5XULRo3qua7rysTvDACAN3E9WIy//RFeVKBwyF/BYn7gHa9bMOuf57KcfssKAOAf/nplBwAAniJYAAAAYwgWAADAGIIFAAAwhmABAACMIVgAAABjCBYAAMAYggUAADCGYAEAAIwhWAAAAGMIFgAAwBiCBQAAMIZgAQAAjCFYAAAAYwgWAADAGIIFAAAwhmABAACMIVgAAABjCBYAAMAYggUAADBmWsHi5MmTKisr04IFC1RVVaVr166Z7gsAAOQh28HiwoUL2rNnj/bv36+bN29qw4YNSiQSGhwcdKI/AACQR2wHi6NHj6qpqUnbt2/XihUrdOzYMcViMbW2tjrRHwAAyCO2gsWzZ8/U39+v2traScdra2t148aNV35NLpdTOp2edAMAAP5kK1g8efJEY2NjKikpmXS8pKREDx8+fOXXJJNJRSKRiVssFpt+twAAYFab1uLNQCAw6b5lWS8dG7d3716lUqmJ29DQ0HRKAgCAPDDfzoMXL16sefPmvXR24vHjxy+dxRgXDAYVDAan3yEAAMgbts5YFBYWqqqqSp2dnZOOd3Z2at26dUYbAwAA+cfWGQtJamlpUUNDg6qrqxWPx3X69GkNDg5qx44dTvQHAADyiO01Ftu2bdOxY8d0+PBhvffee+rp6dGVK1e0dOlSJ/oDJLl3Ubaenh7V1dUpGo0qEAjo4sWLjtRJJpNas2aNQqGQiouLVV9fr7t37zpSq7W1VRUVFQqHwwqHw4rH47p69aojtZzEDEyfX2YA+WFaizd37typ7777TrlcTv39/dq4caPpvoAJbl6ULZvNqrKyUidOnDD+3P+uu7tbzc3N6u3tVWdnp0ZHR1VbW6tsNmu8VmlpqY4cOaK+vj719fVp8+bN2rp1q+7cuWO8llOYgZnxwwwgfwQsy7LcLJhOpxWJRPTTt79VOOSvrUr+GH3P6xaMGrWeq0uXlEqlFA6HPetj7dq1Wr169aSLsK1YsUL19fVKJpOO1Q0EAmpvb1d9fb1jNcb98MMPKi4uVnd3tytBvaioSJ988omampocr2UCM2Bevs0A8oe/XtnhO9O5KFs+SqVSkn75n72TxsbG1NbWpmw2q3g87mgtU5gBs/JxBpBfbC/eBNw0nYuy5RvLstTS0qL169ervLzckRq3b99WPB7X06dPtWjRIrW3t2vlypWO1DKNGTAjn2cA+YVggbxg56Js+WbXrl26deuWrl+/7liN5cuXa2BgQD///LO++OILNTY2qru7O69eWJiBmfHDDCA/ECwwq03nomz5ZPfu3bp8+bJ6enpUWlrqWJ3CwkItW7ZMklRdXa2vv/5ax48f16lTpxyraQozYEY+zwDyC2ssMKv59aJslmVp165d+vLLL/XVV1+prKzM9fq5XM7VmtPFDDhXP19mAPmFMxaY9dy8KNvIyIju3bs3cf/+/fsaGBhQUVGRlixZYqxOc3Ozzp8/r0uXLikUCk38NR6JRLRw4UJjdSRp3759SiQSisViymQyamtrU1dXlzo6OozWcRIzMDN+mAHkDz5uahAfN3XOyZMn9fHHH2t4eFjl5eX69NNPHflIXldXlzZt2vTS8cbGRp07d85YnanWBpw9e1bvv/++sTqS1NTUpL///e8aHh5WJBJRRUWF/vznP2vLli1G6ziNGZg+v8wA8gPBwiCCBQBgrvPXKzsAAPAUwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwQF7I5XI6ePCgK1cKpNbs5defl19rYW7iOhYGcR0L54zPjRu9UGv28uvPy6+1MDf565UdAAB4imABAACMYRMyuO7Fixd68OCBQqHQlPsl/Fo6nZ70TydRazLLspTJZBSNRlVQYOZvkenMgJQfPy8/1nJiBuBfrLEwiDUWb+f7779XLBYz9nxwx9DQkEpLS408FzOQn0zOAPyLMxZwXSgUkiSt1580X+943A3eZFTPdV1XJn5vJjAD+cWJGYB/ESzguvFT3/P1juYHeFGZ9f55TtPOWxZvwgzkGQdmAP7lr/ciAACApwgWAADAGIIFACBvnDx5UmVlZVqwYIGqqqp07do14zV6enpUV1enaDSqQCCgixcvGq8xLplMas2aNQqFQiouLlZ9fb3u3r3rSK3W1lZVVFQoHA4rHA4rHo/r6tWrxusQLAAAeeHChQvas2eP9u/fr5s3b2rDhg1KJBIaHBw0WiebzaqyslInTpww+ryv0t3drebmZvX29qqzs1Ojo6Oqra1VNps1Xqu0tFRHjhxRX1+f+vr6tHnzZm3dulV37twxWoePmxrEx03fzvgM1GgrC/fygBNzwAzkl9lyef+1a9dq9erVam1tnTi2YsUK1dfXK5lMOlIzEAiovb1d9fX1jjz/r/3www8qLi5Wd3e3Nm7c6Hi9oqIiffLJJ2pqajL2nP56ZQcA+NKzZ8/U39+v2traScdra2t148YNj7oyL5VKSfrlBd9JY2NjamtrUzabVTweN/rcfNwUADDrPXnyRGNjYyopKZl0vKSkRA8fPvSoK7Msy1JLS4vWr1+v8vJyR2rcvn1b8XhcT58+1aJFi9Te3q6VK1carcEZC0yLGwuoMPsxB3Dbr6+lYVmWb66vsWvXLt26dUufffaZYzWWL1+ugYEB9fb26oMPPlBjY6O++eYbozUIFrDNrQVUmN2YA7hp8eLFmjdv3ktnJx4/fvzSWYx8tHv3bl2+fFn/+Mc/HL1semFhoZYtW6bq6molk0lVVlbq+PHjRmsQLGDb0aNH1dTUpO3bt2vFihU6duyYYrHYpAVV8D/mAG4qLCxUVVWVOjs7Jx3v7OzUunXrPOpq5izL0q5du/Tll1/qq6++UllZmev1c7mc0edkjQVsGV9A9eGHH046/roFVLlcbtLgurGDI5xldw6YAZjQ0tKihoYGVVdXKx6P6/Tp0xocHNSOHTuM1hkZGdG9e/cm7t+/f18DAwMqKirSkiVLjNZqbm7W+fPndenSJYVCoYkzMpFIRAsXLjRaa9++fUokEorFYspkMmpra1NXV5c6OjqM1iFYwJbpLKBKJpM6dOiQG+3BJXbngBmACdu2bdOPP/6ow4cPa3h4WOXl5bpy5YqWLl1qtE5fX582bdo0cb+lpUWS1NjYqHPnzhmtNX6Gr6amZtLxs2fP6v333zda69GjR2poaNDw8LAikYgqKirU0dGhLVu2GK1DsMC02FlAtXfv3on/MKVf/lply2x/eNs5YAZgys6dO7Vz505Ha9TU1MitSzy5eSmpM2fOuFKHYAFbprOAKhgMKhgMutEeXGJ3DpgBYO5g8SZs8esCKtjDHACYCmcsYJtbC6gwuzEHAF6FYAHb3FpAhdmNOQDwKgQLTIsbC6gw+zEHAH6NNRYAAMAYggUAIG/kcjkdPHjQ+NUiqWWO7WDR09Ojuro6RaNRBQIBXbx40YG2AAB4WS6X06FDh1x7AaaWfbaDRTabVWVlpU6cOOFEPwAAII/ZXryZSCSUSCSc6AUAAOQ5xz8VwuZDAIBXefHihR48eKBQKDTllgC/Nv4a4sZrCbUmsyxLmUxG0WhUBQVTv+HheLBg8yEAwKs8ePBg2nvGuLnXDLUmGxoaUmlp6ZT/3vFgweZDAIBXCYVCkqT1+pPm6x2Pu8GbjOq5ruvKxO9tKo4HCzYfAgC8yvjbH/P1juYHCBaz3j83Yn3T21ZcxwIAABhj+4zFyMiI7t27N3H//v37GhgYUFFRkZYsWWK0OQAAkF9sB4u+vj5t2rRp4v74+onGxkadO3fOWGMAACD/2A4WNTU1sizLiV4AAECeY40FAAAwhmABAACMIVgAAABjCBawjR1uwQxg3MmTJ1VWVqYFCxaoqqpK165d87oleIxgAdvY4RbMACTpwoUL2rNnj/bv36+bN29qw4YNSiQSGhwc9Lo1eMjxK2/Cf9jhFswAJOno0aNqamrS9u3bJUnHjh3T3/72N7W2tiqZTHrcHbxCsIDj2OEWzID/PHv2TP39/frwww8nHa+trdWNGzde+TXMwdzAWyFwXDKZVCQSmbixCd3cwwz4z5MnTzQ2NqaSkpJJx0tKSvTw4cNXfg1zMDcQLOC4vXv3KpVKTdyGhoa8bgkuYwb869cbUlmWNeUmVczB3MBbIXAcO9yCGfCfxYsXa968eS+dnXj8+PFLZzHGMQdzA2csAAC2FRYWqqqqSp2dnZOOd3Z2at26dR51hdmAMxawjR1uwQxA+mUTyoaGBlVXVysej+v06dMaHBzUjh07vG4NHiJYwDZ2uAUzAEnatm2bfvzxRx0+fFjDw8MqLy/XlStXtHTpUq9bg4cIFrCNHW7BDGDczp07tXPnTq/bwCzCGgsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGMPHTQEAnmr/9rbCIf7One3SmRf6j9+/+XH8JgEAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAvYkkwmtWbNGoVCIRUXF6u+vl537971ui24jDmAJPX09Kiurk7RaFSBQEAXL170uiXMAgQL2NLd3a3m5mb19vaqs7NTo6Ojqq2tVTab9bo1uIg5gCRls1lVVlbqxIkTXreCWYS9QmBLR0fHpPtnz55VcXGx+vv7tXHjRo+6gtuYA0hSIpFQIpHwug3MMgQLzEgqlZIkFRUVTfmYXC6nXC43cT+dTjveF9z1pjlgBiAxB3MFb4Vg2izLUktLi9avX6/y8vIpH5dMJhWJRCZusVjMxS7htLeZA2YAEnMwVxAsMG27du3SrVu39Nlnn732cXv37lUqlZq4DQ0NudQh3PA2c8AMQGIO5greCsG07N69W5cvX1ZPT49KS0tf+9hgMKhgMOhSZ3DT284BMwCJOZgrCBawxbIs7d69W+3t7erq6lJZWZnXLcEDzAGAqRAsYEtzc7POnz+vS5cuKRQK6eHDh5KkSCSihQsXetwd3MIcQJJGRkZ07969ifv379/XwMCAioqKtGTJEg87g5dYYwFbWltblUqlVFNTo9/85jcTtwsXLnjdGlzEHECS+vr6tGrVKq1atUqS1NLSolWrVukvf/mLx53BS5yxgC2WZXndAmYB5gCSVFNTwyzgJZyxAAAAxhAsAACAMbaCBRsPAQCA17EVLNh4CAAAvI6txZtsPAQAAF5nRp8KYQMqAMB0jX+iJD3ywuNO8DbGf09v+iTQtIOFnQ2oDh06NN0yAACfymQykqSlq7/zthHYkslkFIlEpvz30w4W4xsPXb9+/bWP27t3r1paWibup9NpdrQDACgajWpoaEihUEiBQOCtvmb8NWRoaEjhcNjR/qg1mWVZymQyikajr33ctIIFG1ABAGaqoKDgja8hUwmHw46/AFPrZa87UzHOVrBg4yEAAPA6toIFGw8BAIDXsXUdCzYeAgB4KRgM6sCBA668xU6t6QlYLu8gk06nFYlE9NO3v1U45K8riv8x+p7XLRg1aj1Xly4plUoZfc9vfAZqtFXzA+8Ye144w4k5YAbyi1P/L4A/+euVHQAAeIpgAQAAjCFYwJbW1lZVVFRMfEwpHo/r6tWrXrcFlzEHAKZCsIAtpaWlOnLkiPr6+tTX16fNmzdr69atunPnjtetwUXMAYCpzGivEMw9dXV1k+5/9NFHam1tVW9vr959912PuoLbmAMAUyFYYNrGxsb0+eefK5vNKh6Pe90OPMIcAPh3BAvYdvv2bcXjcT19+lSLFi1Se3u7Vq5cOeXj2eHWn+zMATMAzB2ssYBty5cv18DAgHp7e/XBBx+osbFR33zzzZSPTyaTikQiEzc2ofMHO3PADABzBxfIMmiuXiDrD3/4g373u9/p1KlTr/z3r/prNRaLcXGkPGFiDpiB/MYFsmAHb4VgxizLmvSi8WvscDs3vG4OmAFg7iBYwJZ9+/YpkUgoFospk8mora1NXV1d6ujo8Lo1uIg5ADAVggVsefTokRoaGjQ8PKxIJKKKigp1dHRoy5YtXrcGFzEHAKZCsIAtZ86c8boFzALMAYCp+Gv1JAAA8BTBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYw8dN4brxq8iP6rnk6gXlMR2jei7pX783E5iB/OLEDMC/CBZwXSaTkSRd1xWPO4EdmUxGkUjE2HNJzEC+MTkD8C+CBVwXjUY1NDSkUCikQCDwVl8zvmnV0NCQ45sgUWsyy7KUyWQUjUaN9TKdGZDy4+flx1pOzAD8i2AB1xUUFKi0tHRaXxsOh13bXZFa/2L6r9SZzIA0+39efqzFmQq8LRZvAgAAYwgWAADAGIIF8kIwGNSBAwcUDAaplQe1nOLXn5dfa2FuClguf34onU4rEonop29/q3DIX7nmj9H3vG7BqFHrubp0SalUyrX3fQEA+c1fr+wAAMBTBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMbYChatra2qqKhQOBxWOBxWPB7X1atXneoNAADkGVvBorS0VEeOHFFfX5/6+vq0efNmbd26VXfu3HGqPwAAkEfm23lwXV3dpPsfffSRWltb1dvbq3fffddoYwAAIP/YChb/bmxsTJ9//rmy2azi8fiUj8vlcsrlchP30+n0dEsCAIBZzvbizdu3b2vRokUKBoPasWOH2tvbtXLlyikfn0wmFYlEJm6xWGxGDQMAgNkrYFmWZecLnj17psHBQf3888/64osv9Ne//lXd3d1ThotXnbGIxWL66dvfKhzy14dS/hh9z+sWjBq1nqtLl5RKpRQOh71uBwCQB2y/FVJYWKhly5ZJkqqrq/X111/r+PHjOnXq1CsfHwwGFQwGZ9YlAADICzM+ZWBZ1qQzEgAAYO6ydcZi3759SiQSisViymQyamtrU1dXlzo6OpzqDwAA5BFbweLRo0dqaGjQ8PCwIpGIKioq1NHRoS1btjjVHwAAyCO2gsWZM2ec6gMAAPiAvz6WAQAAPEWwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAxBAsAAGAMwQIAABhDsAAAAMYQLAAAgDEECwAAYAzBAgAAGEOwAAAAxhAsAACAMQQLAABgDMECAAAYQ7AAAADGECwAAIAx890uaFmWJCk98sLt0o4btZ573YJRo/rl+xn/nQEA8CauB4tMJiNJWrr6O7dLu+B/vW7AEZlMRpFIxOs2AAB5IGC5/Ofoixcv9ODBA4VCIQUCAUdrpdNpxWIxDQ0NKRwOO1rLLW5+T5ZlKZPJKBqNqqCAd80AAG/m+hmLgoIClZaWulozHA77JliMc+t74kwFAMAO/gwFAADGECwAAIAxvg4WwWBQBw4cUDAY9LoVY/z4PQEA/MP1xZsAAMC/fH3GAgAAuItgAQAAjCFYAAAAYwgWAADAGIIFAAAwhmABAACMIVgAAABjCBYAAMCY/wfqW8J62dM6fwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# export\n",
    "class MaskedLinear(nn.Module):\n",
    "    \"Masked linear layer\"\n",
    "    def __init__(self, d_in:int, d_out:int, mask=None):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.randn(d_out, d_in))\n",
    "        self.b = nn.Parameter(torch.zeros(d_out))\n",
    "        if mask is None:\n",
    "            mask = torch.ones(d_out, d_in)\n",
    "        else:\n",
    "            assert mask.size() == self.w.size()\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "        torch.nn.init.kaiming_normal_(self.w)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        if mask is not None:\n",
    "            return F.linear(x, self.w*mask, self.b)\n",
    "        elif self.mask is not None:\n",
    "            return F.linear(x, self.w*self.mask, self.b)\n",
    "        else:\n",
    "            print(\"Using `MaskedLinear` but no mask is provided. Layer acts like nn.Linear\")\n",
    "            return F.linear(x, self.w, self.b)\n",
    "\n",
    "    def set_mask(self, mask:torch.Tensor):\n",
    "        assert mask.size() == self.w.size()\n",
    "        self.mask = mask\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "m = MaskedLinear(d,k)\n",
    "m.set_mask(masks[0])\n",
    "m.mask\n",
    "x = torch.rand(5, d)\n",
    "out1 = m(x)\n",
    "\n",
    "x[:, 1] = torch.rand(5)\n",
    "out2 = m(x)\n",
    "assert torch.all(out1 == out2)\n",
    "out2\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.8757, -0.0918,  0.1242,  0.4327],\n",
       "        [-0.8374, -0.0877,  0.1188,  0.4137],\n",
       "        [-0.2710, -0.0284,  0.0385,  0.1339],\n",
       "        [-0.0614, -0.0064,  0.0087,  0.0303],\n",
       "        [-0.5964, -0.0625,  0.0846,  0.2947]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# export\n",
    "class SimpleMADE(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in:int, d_h:int, n_layers:int, add_direct=True):\n",
    "        super().__init__()\n",
    "        dims = [d_in] + [d_h]*n_layers + [d_in]\n",
    "        masks = make_masks(d_in, dims[1:-1])\n",
    "        layers = [MaskedLinear(dims[i], dims[i+1], masks[i]) for i in range(len(masks))]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        if add_direct:\n",
    "            self.direct = MaskedLinear(d_in, d_in, torch.tril(torch.ones(d_in, d_in), diagonal=-1))\n",
    "        else:\n",
    "            self.direct = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        if self.direct is not None:\n",
    "            out += self.direct(x)\n",
    "        return out\n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = SimpleMADE(2, 4, 2, True)\n",
    "model\n",
    "x = torch.rand(5, 2)\n",
    "model(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.0571],\n",
       "        [ 0.0000, -0.0635],\n",
       "        [ 0.0000, -0.4485],\n",
       "        [ 0.0000, -0.1129],\n",
       "        [ 0.0000, -0.0245]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# hide\n",
    "class MADE(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in:int, d_h:int, n_layers:int, add_direct=True, outs_per_input=1):\n",
    "        super().__init__()\n",
    "        self.outs_per_input = outs_per_input\n",
    "        dims = [d_in] + [d_h]*n_layers + [d_in*outs_per_input]\n",
    "        self.masks = make_masks(d_in, dims[1:-1])\n",
    "        layers = [MaskedLinear(dims[i], dims[i+1], self.masks[i]) for i in range(len(self.masks)-1)]\n",
    "        layers += [MaskedLinear(dims[-2], dims[-1])]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        if add_direct:\n",
    "            direct_mask = torch.repeat_interleave(\n",
    "                torch.tril(torch.ones(d_in, d_in), diagonal=-1), outs_per_input, 0\n",
    "            )\n",
    "            self.direct = MaskedLinear(d_in, d_in*outs_per_input, direct_mask)\n",
    "        else:\n",
    "            self.direct = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers[:-1]:\n",
    "            out = layer(out)\n",
    "        out = self.layers[-1](out, mask=torch.repeat_interleave(self.masks[-1], self.outs_per_input, 0))\n",
    "\n",
    "        if self.direct is not None:\n",
    "            out += self.direct(x)\n",
    "        return out\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# export\n",
    "class MADE(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in:int, d_h:int, n_layers:int, add_direct=True, outs_per_input=1):\n",
    "        super().__init__()\n",
    "        self.outs_per_input = outs_per_input\n",
    "        dims = [d_in] + [d_h]*n_layers + [d_in*outs_per_input]\n",
    "        self.masks = make_masks(d_in, dims[1:-1])\n",
    "        layers = [MaskedLinear(dims[i], dims[i+1], self.masks[i]) for i in range(len(self.masks)-1)]\n",
    "        layers += [MaskedLinear(dims[-2], dims[-1])]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        if add_direct:\n",
    "            direct_mask = torch.tril(torch.ones(d_in, d_in), diagonal=-1).repeat(outs_per_input,1)\n",
    "            self.direct = MaskedLinear(d_in, d_in*outs_per_input, direct_mask)\n",
    "        else:\n",
    "            self.direct = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers[:-1]:\n",
    "            out = layer(out)\n",
    "        out = self.layers[-1](out, mask=self.masks[-1].repeat(self.outs_per_input,1))\n",
    "\n",
    "        if self.direct is not None:\n",
    "            out += self.direct(x)\n",
    "        return out\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "x=torch.arange(10).reshape(2,5)\n",
    "x.repeat(1,2)\n",
    "x = torch.rand(5, 2)\n",
    "model = MADE(2, 4, 3, outs_per_input=2)\n",
    "model(x)\n",
    "d_in = 4\n",
    "outs_per_input = 2\n",
    "direct_mask = torch.repeat_interleave(\n",
    "    torch.tril(torch.ones(d_in, d_in), diagonal=-1), outs_per_input, 0\n",
    ")\n",
    "direct = MaskedLinear(d_in, d_in*outs_per_input, direct_mask)\n",
    "direct_mask\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 1., 0.],\n",
       "        [1., 1., 1., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted 00_layers.ipynb.\n",
      "Converted 01_training.ipynb.\n",
      "Converted 02_made.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('torchenv': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "4af15c6377fd3f0f03723b0d6472f0c10dcd7b2afd49a75a2b51cefc0e0a1d19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}